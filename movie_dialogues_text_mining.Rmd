---
title: "subtittle_text_mining"
author: "Adam Kolipi≈Ñski, Ludwik Przyrowski"
date: "27 maja 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=FALSE)
```

## biblioteki
```{r, message=F}
# calculations
library(tm) 
library(dplyr)
library(SnowballC)

#visualization
library(wordcloud2)
```
## wstÍp
Celem projektu jest znalezienie najbardziej pozytywnych filmÛw ze zbioru. 
èrÛd≥o dialogÛw pochodzi z serwisu https://nlds.soe.ucsc.edu/fc2. Pliki podzielone sπ na kategorie:
```{r}

path = file.path(getwd(), "dialogs/")
category_list = dir(path)
category_list
```
W celu przyúpieszenia procesu ograniczono siÍ tylko do czÍúci kategorii.
```{r}

path = file.path(getwd(), "dialogs_selected/")
category_list = dir(path)
category_list
```
wszystkie filmy w podkategoriach zosta≥y zaimportowane do "korpusu"
```{r}
corpus <- Corpus(DirSource(path, recursive=T))
```
  
W uzyskanym ürÛdle imiona bohaterÛw oraz opisy sA pisane samymi duøymi literami.
Dlatego napisana zosta≥a niestandardowa funkcja dla preprocessingu, usuwajπca takie wystπpienia
UsuniÍte bÍdzie w ten sposÛb rÛwnieø kilku okrzykÛw ale ich wp≥yw uznany jest za nieznaczny.
 
```{r}
remAllCap <- function (x){gsub("\\b[A-Z]+\\b", "", x)}
corpus <- tm_map(corpus, remAllCap)
```

 
Zastosowano seriÍ narzÍdzi do odpowiedniej obrÛbki wstÍpnej dialogÛw oraz zamaskowano bardzo popularnego angielskiego przekleÒstwa:
```{r}
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("english")))
remSwer <- function(x){gsub("fuck", "f**k", x)}
corpus <- tm_map(corpus, remSwer)
corpus_org <-corpus
corpus_org <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stripWhitespace)

```

   
Utoworzenie Macierzy wyraøenie-dokument

```{r}

tdm <- TermDocumentMatrix(corpus)
```
  
analiza pozytywnego lub negatywnego znaczenia dialogÛw na podstawie wystÍpowania s≥Ûw pozytywnych lub negatywnych. 

Uøyta zosta≥a lekko zmodyfikowana funkcja przerabiana na zajÍciach. Przerobiony zosta≥ wynik funkcji jako rÛønica udzia≥u procentowego pozytywnych i negatywnych s≥Ûw do wszystkich negatywnych i pozytywnych s≥Ûw.
Za s≥owniki negatywnych i pozytywnych s≥Ûw zosta≥y urzyta baza prezentowana w instrukcji do zajÍÊ.

```{r}
hu.liu.pos = scan(file.path(getwd(), "opinion-lexicon-English","positive-words.txt"),
                  what='character', comment.char=';')
hu.liu.neg = scan(file.path(getwd(), "opinion-lexicon-English","negative-words.txt"),
                  what='character', comment.char=';')

score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
  require(plyr)
  require(stringr)
  scores = laply(sentences, function(sentence, pos.words, neg.words) {
    word.list = str_split(sentence, '\\s+')
    words = unlist(word.list)
    pos.matches = match(words, pos.words)
    neg.matches = match(words, neg.words)
    pos.matches = !is.na(pos.matches)
    neg.matches = !is.na(neg.matches)
    score = c(sum(pos.matches)/length(words), sum(neg.matches)/length(words))
    return(score)
  }, pos.words, neg.words, .progress=.progress )
}
```
Funkcja zosta≥a uøyta do wczeúniej zaczytanego cia≥a:

```{r, message=F}
max = length(list.files(path=path, recursive = T))

i <- 1
names = c()
pos = c()
neg=c()

while(i<=max){
  sample.text = corpus[[i]]$content
  result = score.sentiment(sample.text, hu.liu.pos , hu.liu.neg)
  names = c(names, gsub("_dialog.txt","",corpus[[i]]$meta$id))
  pos = c(pos, result[1])
  neg = c(neg, result[2])
  i=i+1
}
```

Wyniki ograniczono tylko do tych filmÛw w ktÛrych pozytywne i negatywne wyraøenia stanowi≥y co najmniej 5% wszystkich wyraøeÒ.
```{r}
df = data.frame(names, pos, neg )
df <- df %>% filter(pos >0.5 & neg >0.5) %>% distinct() %>% mutate(per_pos = pos/(pos+neg))
df.pos <- df %>%  arrange(desc(per_pos)) 
df.neg <- df %>%  arrange(per_pos) 
```
W ten sposÛb uda≥o sie wyodrÍbniÊ najbardziej pozytywne filmy w zbiorze:
```{r}
top_n(df.pos, 15)
```

Oraz najbardziej negarywne filmy w zbiorze:
```{r}
top_n(df.neg, -15)
```
Ostatnim etapem jest wizualizacja czÍstoúci wystÍpowania s≥Ûw poprzez chmurÍ wyrazÛw. 
Ca≥oúÊ przygotowania zosta≥π zamkniÍta w postaci funkcji:
```{r}

for.cloud = function(name, names, corpus_org){
  id = match(name, names)
  print(corpus_org[[id]]$meta$id)
  print(id)
  ##POS taging
  library(NLP)
  library(openNLP)
  library(tm)
  sent_token_annotator <-  Maxent_Sent_Token_Annotator()
  word_token_annotator <-  Maxent_Word_Token_Annotator()
  sample.text = corpus_org[[id]]$content
  a1 = annotate(sample.text,list(sent_token_annotator,word_token_annotator))
  pos_tag_annotator <-  Maxent_POS_Tag_Annotator()
  a3 = annotate(sample.text, pos_tag_annotator, a1)
  a3w = subset(a3, type=='word')
  max = length(a3w)
  k = 1
  words = c()
  while(k<=max){
    p = unlist(a3w[k]$features)
    if(p=="NN" || p=="VB"){
      word <- substr(sample.text,a3w[k]$start, a3w[k]$end)
    }
    words = c(words, word)
    k = k + 1
  }
  words= words[words!='m' & words!='ll' & words!="ve" & words!="dont"]
  tb <- as.data.frame(table(words))
  colnames(tb) <- c('word','freq')
  tb <- tb %>% arrange(desc(freq))
  return(tb)
}
```
Poniøej przyk≥ad jednego z pozytywnych filmÛw: Amadeus

```{r}
words.pos <- for.cloud('amadeus', names, corpus_org)
#path.png = file.path(getwd(), "sample pictures/play.png")
#wordcloud2(data = words.neg, figPath = path.png, size = 1.5)
```
![Caption for the picture.](amadeus.png)
oraz negatywny "Pine Apple Express"

```{r}
#words.neg <- for.cloud('pineappleexpress', names, corpus_org)
path.png = file.path(getwd(), "sample pictures/movie.png")
#wordcloud2(data = words.pos, figPath = path.png, size = 1)
```
![Caption for the picture.](pineappleexpress.png)

Oraz bonusowy pozytywn "Notting Hill""
![Caption for the picture.](nottinghill.png)
