---
title: "subtittle_text_mining"
author: "Adam KolipiÒski, Ludwik Przyrowski"
date: "27 maja 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

## biblioteki
```{r, message=F}
# calculations
library(tm) 
library(dplyr)
library(SnowballC)

#visualization
library(wordcloud2)
```
## wstÍp

èrÛd≥o dialogÛw https://nlds.soe.ucsc.edu/fc2
```{r}

path = file.path(getwd(), "dialogs/")
category_list = dir(path)
category_list
```

```{r}

path = file.path(getwd(), "dialogs_selected/")
category_list = dir(path)
category_list
```

```{r}
corpus <- Corpus(DirSource(path, recursive=T))
```
  
W uzyskanym ürÛdle imiona bohaterÛw oraz opisy sA pisane samymi duøymi literami.
Dlatego napisana zosta≥a niestandardowa funkcja dla preprocessingu, usuwajπca takie wystπpienia
UsuniÍte bÍdzie w ten sposÛb rÛwnieø kilku okrzykÛw ale ich wp≥yw uznany jest za nieznaczny.
 
```{r}
remAllCap <- function (x){gsub("\\b[A-Z]+\\b", "", x)}
corpus <- tm_map(corpus, remAllCap)
```

 
standardowe funkcjie data cleaning oraz zamaskowanie bardzo popularnego angielskiego przekleÒstwa:
```{r}
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("english")))
remSwer <- function(x){gsub("fuck", "f**k", x)}
corpus <- tm_map(corpus, remSwer)
corpus_org <-corpus
corpus_org <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stripWhitespace)

```

   
Utoworzenie Macierzy wyraøenie-dokument

```{r}

tdm <- TermDocumentMatrix(corpus)
```
  
analiza pozytywnego lub negatywnego znaczenia dialogÛw na podstawie wystÍpowania s≥Ûw pozytywnych lub negatywnych. 

Uøyta zosta≥a lekko zmodyfikowana funkcja przerabiana na zajÍciach. Przerobiony zosta≥ wynik funkcji jako rÛønica udzia≥u procentowego pozytywnych i negatywnych s≥Ûw do wszystkich negatywnych i pozytywnych s≥Ûw.
Za s≥owniki negatywnych i pozytywnych s≥Ûw zosta≥y urzyta baza prezentowana w instrukcji do zajÍÊ.

```{r}
hu.liu.pos = scan(file.path(getwd(), "opinion-lexicon-English","positive-words.txt"),
                  what='character', comment.char=';')
hu.liu.neg = scan(file.path(getwd(), "opinion-lexicon-English","negative-words.txt"),
                  what='character', comment.char=';')

score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
  require(plyr)
  require(stringr)
  scores = laply(sentences, function(sentence, pos.words, neg.words) {
    word.list = str_split(sentence, '\\s+')
    words = unlist(word.list)
    pos.matches = match(words, pos.words)
    neg.matches = match(words, neg.words)
    pos.matches = !is.na(pos.matches)
    neg.matches = !is.na(neg.matches)
    score = c(sum(pos.matches)/length(words), sum(neg.matches)/length(words))
    return(score)
  }, pos.words, neg.words, .progress=.progress )
}
```
Funkcja zosta≥a uøyta do wczeúniej zaczytanego cia≥a:

```{r, message=F}
max = length(list.files(path=path, recursive = T))

i <- 1
names = c()
pos = c()
neg=c()

while(i<=max){
  sample.text = corpus[[i]]$content
  result = score.sentiment(sample.text, hu.liu.pos , hu.liu.neg)
  names = c(names, gsub("_dialog.txt","",corpus[[i]]$meta$id))
  pos = c(pos, result[1])
  neg = c(neg, result[2])
  i=i+1
}
df = data.frame(names, pos, neg )
df <- df %>% filter(pos >0 & neg >0) %>% distinct() %>% mutate(per_pos = pos/(pos+neg))
df.pos <- df %>%  arrange(desc(per_pos)) 
df.neg <- df %>%  arrange(per_pos) 
```
najbardziej pozytywne filmy w zbiorze
```{r}
top_n(df.pos, 15)
```



najbardziej negarywne filmy w zbiorze
```{r}
top_n(df.neg, -15)
```
"
A group of suburban biker wannabes looking for adventure hit the open road, but get more than they bargained for when they encounter a New Mexico gang called the Del Fuegos. 
"
from http://www.imdb.com


funkcja do przygotowania word clouds:
```{r}
for.cloud = function(name, names, corpus_org){
  id <- match(name, names)
  ##POS taging
  library(NLP)
  library(openNLP)
  library(tm)
  sent_token_annotator <-  Maxent_Sent_Token_Annotator()
  word_token_annotator <-  Maxent_Word_Token_Annotator()
  sample.text = corpus_org[[id]]$content
  a1 <- annotate(sample.text,list(sent_token_annotator,word_token_annotator))
  pos_tag_annotator <-  Maxent_POS_Tag_Annotator()
  a3 <- annotate(sample.text, pos_tag_annotator, a1)
  a3w <- subset(a3, type=='word')
  max = length(a3w)
  k = 1
  words = c()
  while(k<=max){
    p = unlist(a3w[k]$features)
    #if(p=="VB" || p=="NN"){
    if(p=="NN" || p=="VB"){
      word <- substr(sample.text,a3w[k]$start, a3w[k]$end)
    }
    words = c(words, word)
    k = k + 1
  }
  words= words[words!='m' & words!='ll' & words!="ve" & words!="dont"]
  tb <- as.data.frame(table(words))
  colnames(tb) <- c('word','freq')
  tb <- tb %>% arrange(desc(freq))
  return(tb)
}
words <- for.cloud('nottinghill', names, corpus_org)

```
Na podstawie wynikÛw zosta≥a stworzona wizualizacja za pomocπ biblioteki 'wroldcloud2' dla filmÛw

pozytywny:
Notting hill
words <- for.cloud('nottinghill', names, corpus_org)

oraz negatywny

```{r} 
#set.seed(123)
#m <- as.matrix(tdm)
#v <- sort(rowSums(m), decreasing=TRUE)
#words <- names(v)
#d <- data.frame(word=words, freq=v)
#path.png = file.path(getwd(), "sample pictures/movie.png")
#path.png = file.path(getwd(), "sample pictures/action.png")
#pct <- wordcloud2(data = d, figPath = path.png, size = 1.5)
```
![Caption for the picture.](word_clod_action.png)

